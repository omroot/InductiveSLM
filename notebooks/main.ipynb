{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import gc\n",
    "from typing import Dict, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.deer import DeerToTriplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.utils import to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.inference.inference import build_inference_prompt, generate_answers_with, PromptAnswerCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.evaluate import eval_metrics, print_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.io.read import RawDataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.settings import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as cfg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdr = RawDataReader(Settings.paths.RAW_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir_triplets_dataset = rdr.read_ir_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer_dataset = rdr.read_deer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer_to_triplets_converter = DeerToTriplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "deer_to_triplets_converter.process(deer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] =  cfg.HUGGINGFACE_HUB_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = os.environ[\"HUGGINGFACE_HUB_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import random\n",
    "import gc\n",
    "from typing import Dict, List\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    GenerationConfig\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a40ed1dd3f4867928f0250a9682444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val_data = deer_to_triplets_converter.triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - GPU Optimized\n",
    "MODEL_ID =cfg.MODEL_ID  \n",
    "OUTPUT_DIR =cfg.OUTPUT_DIR  \n",
    "SEED =cfg.SEED  \n",
    "VAL_FRACTION =cfg.VAL_FRACTION  \n",
    "MAX_SEQ_LEN =cfg.MAX_SEQ_LEN  \n",
    "\n",
    "# LoRA Configuration - Larger for GPU\n",
    "LORA_R =cfg.LORA_R  \n",
    "LORA_ALPHA =cfg.LORA_ALPHA  \n",
    "LORA_DROPOUT =cfg.LORA_DROPOUT  \n",
    "TARGET_MODULES =cfg.TARGET_MODULES  \n",
    "\n",
    "# Training Configuration - GPU Optimized\n",
    "LR =cfg.LR  \n",
    "EPOCHS =cfg.EPOCHS  \n",
    "BATCH_SIZE =cfg.BATCH_SIZE  \n",
    "GRAD_ACCUM =cfg.GRAD_ACCUM  \n",
    "LOG_STEPS =cfg.LOG_STEPS  \n",
    "EVAL_STEPS =cfg.EVAL_STEPS  \n",
    "SAVE_STEPS =cfg.SAVE_STEPS  \n",
    "GEN_MAX_NEW_TOKENS =cfg.GEN_MAX_NEW_TOKENS  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ir_triplets_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 1264\n",
      "Validation examples: 543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "# Split data\n",
    "random.Random(SEED).shuffle(data)\n",
    "split_idx = int(len(data) * (1 - VAL_FRACTION))\n",
    "train_raw, val_raw = data[:split_idx], data[split_idx:]\n",
    "\n",
    "\n",
    "# train_raw = data #, _ = data[:split_idx], data[split_idx:]\n",
    "# val_raw = val_data\n",
    " \n",
    "\n",
    "\n",
    "print(f\"Training examples: {len(train_raw)}\")\n",
    "print(f\"Validation examples: {len(val_raw)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244,
     "referenced_widgets": [
      "63b8888f57b349f48d6188ad4972943f",
      "17b86021cf0e4ce9b6268fa3219f6a72",
      "3d068bd55fda46c8b7f7103360273068",
      "ae050d75805644e0ae67b049274f663d",
      "d6b60c1a50b34be3b95483f40c6f917c",
      "0356ada1f1db4be5915430571aed376b",
      "c72d54cb5f3e4d40b493c873a91fede9",
      "6229068e4ff64754afbc59b87bd25fe0",
      "0170fbfab7d84acb9aea90af6cfe8ac9",
      "fad327a9f8594bddb8d251a29d628247",
      "4f47112e71024fc0b8a15b63e6a1f904",
      "60239336787f4ec9aa23dd423f8cadea",
      "195e6762c5fe4ef6b3610a7fba603a39",
      "73f4c63ba2584fc18c238e9a415e6f80",
      "af95dfe9d015476c9d4028d08acc3808",
      "9561d1e3450b4efab66428acb50a5b2e",
      "826d0838dc55426798bb9a64516fe8d8",
      "fba88cc6c1e74832be0d04f5034ad784",
      "27d8c97e9dea4fe3aeba4465acb82bf6",
      "128b922e6719460abf38f59f90afa141",
      "5eb7823cfc4f4f409bba02a87f4c6edd",
      "08fa103731d64465a0f0af86e625fd37",
      "b1108d37b1fb4d75ae85646f4907120c",
      "f07d1f229e83424a9cf8090220ce1f83",
      "27f8e121a7034eed857d4e9fc5e1d2da",
      "66334026a6344f99811b85dea929fb3a",
      "01270c24ebb94ccf8ac18553ffd6f127",
      "f8587ec101a54fe7a37c243b5c142f6f",
      "ce602d66b833431cad5a002513eed8ee",
      "01b7f699ab264d00b6caa17de44b5998",
      "9f0bd5b80b1848c08ca5df3906845641",
      "79373e72d9a2414a9a2c0200a141e7b5",
      "4c46cefbfd5847c9919861085ec9c202",
      "e24c12bde94a4305bb546c886da4ab4e",
      "0bdab12747cd4d1e9d352ca569857d37",
      "22968273507842a086ee0c1972f76a8f",
      "a5c03a39ca3c401fadaf772eadd48705",
      "204ba879c2f640d5829329dfaefa459c",
      "10b54896c99541868d7e42ef247abe8e",
      "6ae3f035d2d84f2ebb2a530a1ba6775f",
      "60b3e147812e4ac8ba56e94bb939f341",
      "1aaf1c10e76a409f9eb3cb4d2fca4c3d",
      "79c890e48ed6498fbbfcbb850852e85e",
      "b93c9b095f6b4b419f0b190ef5d75930",
      "89485c97ce8d40c298081aa2f50dc0d0",
      "296625f11fff40289d289d6d6216cf05",
      "ee3f6dd5d1854e70ad0ec7f9f833b16b",
      "3e349c08386b4c16be10fdc1a1a91c1f",
      "d80e579ebdcd42f8a4cdbf5025f5a060",
      "6e98521c424e486b8dc57cde87f988f8",
      "c688a09748db4a56a4b4120722c0a00b",
      "b74bc3c945cf47cf9b7e7cc5dc9d27fd",
      "48c3d51ac541454d8198991326362c1d",
      "5b0c3f95d29b4da9a28e0235f35a3024",
      "0359068a3891480293de86020984b66f",
      "32af97df10f942be899dec45a3c0998b",
      "dae40a95088f4887a96553aef9ed29b0",
      "ae0791aee6cd4cdda34298f2e15a753b",
      "075f39c701714e2bac541e0290a686a8",
      "2eb4a2e275044d6f84ee610078a3ff52",
      "d99e1da787824dda88ac629440bbb6be",
      "21eafa9e2c624b4d90786f0e03498aa3",
      "9b9d397152da4a06b22fed13a61c2fdb",
      "0496113c98fa43d68845109e0a2e1399",
      "142a6f0fc7c5477587bb8db7a80f800d",
      "d80007f7a2f6471bb06032ff16e880ff"
     ]
    },
    "id": "YVzsgk10C_Kq",
    "outputId": "6c520529-ea5b-435e-b4e4-55d5457df174",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "train_ds = Dataset.from_list([to_text(x) for x in train_raw])\n",
    "val_ds = Dataset.from_list([to_text(x) for x in val_raw])\n",
    "ds = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "\n",
    "# Prepare validation data for evaluation\n",
    "val_prompts = ds[\"validation\"][\"prompt\"]\n",
    "val_obs = [p.split(\"Question:\\n\")[0].replace(\"Training Observations:\\n\", \"\").strip() for p in val_prompts]\n",
    "val_qs = [p.split(\"Question:\\n\")[1].split(\"\\n\\nAnswer:\\n\")[0].strip() for p in val_prompts]\n",
    "val_refs = [x.strip() for x in ds[\"validation\"][\"response\"]]\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, token=HF_TOKEN)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load evaluation metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"sacrebleu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "# (optional) also wrap .generate in autocast(bfloat16) as in A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating baseline predictions...\")\n",
    "baseline_preds = generate_answers_with(baseline_model,tokenizer,val_obs, val_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline_metrics = eval_metrics(baseline_preds, val_refs, rouge, bleu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e59a8a878f6f4abdb08bbf2688ae8bb7",
      "f85d0290c37947baabae42394b8cda83",
      "ecf312119cdf4d97a2aca40eba42bb49",
      "2feb78d47e974a0ab763da474efe69d9",
      "0c0ab7d35d7b4270844abb3a1ff16cea",
      "96468ec145b441a59ec465147a18b473",
      "4c27d4bad3c54404a16ba495237d57eb",
      "aa2ec039a26e4990a0b3f9d86c22817d",
      "0d4a344223ac443087ad45b49819fed9",
      "ba113e9d81c24a2292d189d8a4179d13",
      "480e8943a95e4eb58a1581e6ec88f17e",
      "7fd2fd1d06fa4a4b8936d306d0d7e5b0",
      "760d47271daf4e8d85123cdc5aa60066",
      "3994b54476f04c3ca9e94aceeb4d57dc",
      "a96165cd912d43c9b2006e4f4e3a02a6",
      "74b7e62cf79345db93b297e9d11b0fc6",
      "94fb311bd9a344d8b973b76d8ee9b4c2",
      "f594598d2e834e7dbcaa40a2b7c4df35",
      "73cd45a3b06f4a69ab88078c6c0a8e3b",
      "63258537bf3846fa80c246dc386cbf09",
      "bec9dae8c0e545ca8c836eb43db0f3d1",
      "d12770ffbc544bf1b2c819e86cf473a9",
      "131f33981c024d74a71c456b84be64ef",
      "22bd82b7046a4163888dbf4df722f189",
      "ce7471ce4c9e448e9a0f5870a34b9f29",
      "8662c5aac3a54da89a383f773c20f802",
      "bb0a6728035949419b53fd5ecaf39b19",
      "845154e7b9364b3ab7aa50bcd7c22b88",
      "416dd330e80347a88e4fb6b4a0971566",
      "38d04e5463744d3f88ba6eb44ccf38b8",
      "585c22b39a48403dadfed290ce562087",
      "7941de3cc39841f28ed46edd081de5b4",
      "d3e5253af22c4937809d3fa1fa7c17c3"
     ]
    },
    "id": "bi4Unw-xC_IN",
    "outputId": "47cfcbec-36db-4493-dad9-7bef28bf1f16",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline metrics: {'rouge1': np.float64(0.02747859826509425), 'rouge2': np.float64(0.002061315914361044), 'rougeL': np.float64(0.022668664160191032), 'rougeLsum': np.float64(0.022727330004289076), 'bleu': 0.02064748741328389}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Baseline metrics:\", baseline_metrics)\n",
    "\n",
    "# Save baseline predictions\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "with open(os.path.join(OUTPUT_DIR, \"val_predictions_baseline.jsonl\"), \"w\") as f:\n",
    "    for obs, q, ref, pred in zip(val_obs, val_qs, val_refs, baseline_preds):\n",
    "        f.write(json.dumps({\n",
    "            \"Training Observations\": obs,\n",
    "            \"Question\": q,\n",
    "            \"Reference\": ref,\n",
    "            \"Prediction\": pred\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Free baseline model memory\n",
    "# del baseline_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # Clear GPU memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1dyiPXPGDPF",
    "outputId": "4440c9cd-11ae-4d06-d3b8-8b1eb93a99f9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDTlijGgOqlG",
    "outputId": "b2445502-1ba1-4adf-a330-39e6f88f00e2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "YatogRZtPjOg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True, token = HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzk8O_EThApz",
    "outputId": "761a0317-e6c2-42ee-974b-97d5c09a5ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.8.0 cuda: None gpu? False\n"
     ]
    }
   ],
   "source": [
    "print(\"torch:\", torch.__version__, \"cuda:\", torch.version.cuda, \"gpu?\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IRon0jvQPl2-"
   },
   "outputs": [],
   "source": [
    "\n",
    "bnb_cfg = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eB9cdcaDlRGt",
    "outputId": "347425a1-739d-4384-ee6c-8f0082cc67de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.8.0 CUDA build: None GPU available: False\n"
     ]
    }
   ],
   "source": [
    "import torch, sys, platform\n",
    "print(\"Torch:\", torch.__version__, \"CUDA build:\", torch.version.cuda, \"GPU available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "b4pMhAR_Ps6p"
   },
   "outputs": [],
   "source": [
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     quantization_config=bnb_cfg,\n",
    "#     device_map=\"auto\",\n",
    "#     low_cpu_mem_usage=True,\n",
    "# )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float32,  # Load in float32 first\n",
    "    # Don't use device_map for now to avoid potential issues\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "0no0ZM-3GJOs"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QxrNbvFGJMf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "QoWYhcy9GKMV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "# # Step 2: Fine-tune model\n",
    "# print(\"Loading model for fine-tuning...\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_ID,\n",
    "#     torch_dtype=torch.float32,  # Load in float32 first\n",
    "#     # Don't use device_map for now to avoid potential issues\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# Move model to GPU manually\n",
    "# model = model.cuda()\n",
    "\n",
    "# Apply LoRA\n",
    "peft_config = LoraConfig(\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=TARGET_MODULES\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDq77clJGKKm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ouvi3ct_GKIR",
    "outputId": "a2667edb-f433-4e06-d0f5-b94fe4face0f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient requirements:\n",
      "  Frozen: base_model.model.model.embed_tokens.weight - shape: torch.Size([151936, 896])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.0.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.0.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.0.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.0.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.0.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.1.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.1.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.1.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.1.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.1.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.2.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.2.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.2.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.2.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.2.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.3.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.3.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.3.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.3.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.3.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.4.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.4.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.4.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.4.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.4.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.5.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.5.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.5.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.5.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.5.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.6.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.6.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.6.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.6.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.6.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.7.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.7.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.7.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.7.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.7.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.8.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.8.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.8.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.8.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.8.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.9.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.9.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.9.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.9.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.9.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.10.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.10.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.10.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.10.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.10.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.11.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.11.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.11.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.11.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.11.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.12.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.12.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.12.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.12.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.12.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.13.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.13.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.13.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.13.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.13.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.14.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.14.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.14.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.14.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.14.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.15.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.15.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.15.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.15.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.15.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.16.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.16.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.16.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.16.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.16.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.17.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.17.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.17.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.17.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.17.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.18.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.18.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.18.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.18.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.18.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.19.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.19.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.19.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.19.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.19.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.20.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.20.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.20.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.20.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.20.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.21.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.21.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.21.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.21.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.21.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.22.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.22.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.22.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.22.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.22.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.q_proj.base_layer.bias - shape: torch.Size([896])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.k_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight - shape: torch.Size([128, 896])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.v_proj.base_layer.bias - shape: torch.Size([128])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight - shape: torch.Size([128, 16])\n",
      "  Frozen: base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight - shape: torch.Size([896, 896])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight - shape: torch.Size([16, 896])\n",
      "  Trainable: base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight - shape: torch.Size([896, 16])\n",
      "  Frozen: base_model.model.model.layers.23.mlp.gate_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.23.mlp.up_proj.weight - shape: torch.Size([4864, 896])\n",
      "  Frozen: base_model.model.model.layers.23.mlp.down_proj.weight - shape: torch.Size([896, 4864])\n",
      "  Frozen: base_model.model.model.layers.23.input_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.layers.23.post_attention_layernorm.weight - shape: torch.Size([896])\n",
      "  Frozen: base_model.model.model.norm.weight - shape: torch.Size([896])\n",
      "Trainable: 2162688, Total: 496195456\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight\n",
      "Enabled gradients for: base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight\n",
      "Trainable parameters:\n",
      "trainable params: 2,162,688 || all params: 496,195,456 || trainable%: 0.4359\n",
      "Testing data collator...\n",
      "Batch shapes: ['input_ids: torch.Size([2, 86])', 'attention_mask: torch.Size([2, 86])', 'labels: torch.Size([2, 86])']\n",
      "Starting fine-tuning...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [237/237 05:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.836300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.722100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.574800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.526800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.574800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.386800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.291400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.223500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating fine-tuned predictions...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "generate_answers_with() missing 1 required positional argument: 'q_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 70\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Step 3: Evaluate fine-tuned model\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating fine-tuned predictions...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m finetuned_preds \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answers_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_qs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m finetuned_metrics \u001b[38;5;241m=\u001b[39m eval_metrics(finetuned_preds, val_refs)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuned metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m, finetuned_metrics)\n",
      "File \u001b[0;32m~/miniconda3/envs/mimesis/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: generate_answers_with() missing 1 required positional argument: 'q_list'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Debug: Check which parameters require gradients\n",
    "print(\"Checking gradient requirements:\")\n",
    "trainable_params = 0\n",
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    total_params += param.numel()\n",
    "    if param.requires_grad:\n",
    "        trainable_params += param.numel()\n",
    "        print(f\"  Trainable: {name} - shape: {param.shape}\")\n",
    "    else:\n",
    "        print(f\"  Frozen: {name} - shape: {param.shape}\")\n",
    "\n",
    "print(f\"Trainable: {trainable_params}, Total: {total_params}\")\n",
    "\n",
    "# Explicitly enable gradients for LoRA parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name.lower():\n",
    "        param.requires_grad_(True)\n",
    "        print(f\"Enabled gradients for: {name}\")\n",
    "\n",
    "print(\"Trainable parameters:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Training arguments - GPU optimized\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=2,  # Reduced for float32 memory usage\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    logging_steps=LOG_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=2,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.03,\n",
    "    load_best_model_at_end=False,\n",
    "    gradient_checkpointing=False,  # Disable to avoid potential LoRA conflicts\n",
    "    report_to=\"none\",\n",
    "    # Disable mixed precision for now to avoid LoRA compatibility issues\n",
    "    dataloader_pin_memory=True,  # Enable for GPU\n",
    "    dataloader_num_workers=0,  # Set to 0 to avoid potential issues\n",
    "    remove_unused_columns=False,\n",
    "    prediction_loss_only=True,\n",
    "    eval_strategy=\"no\",  # Disable evaluation during training for speed\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = PromptAnswerCollator(tokenizer, max_seq_len=MAX_SEQ_LEN)\n",
    "\n",
    "# Test data collator\n",
    "print(\"Testing data collator...\")\n",
    "test_batch = data_collator([ds[\"train\"][0], ds[\"train\"][1]])\n",
    "print(f\"Batch shapes: {[f'{k}: {v.shape}' for k, v in test_batch.items()]}\")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Evaluate fine-tuned model\n",
    "print(\"Generating fine-tuned predictions...\")\n",
    "finetuned_preds = generate_answers_with(model, tokenizer, val_obs, val_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned metrics: {'rouge1': np.float64(0.04165053704125564), 'rouge2': np.float64(0.007719141805907616), 'rougeL': np.float64(0.03287722479511852), 'rougeLsum': np.float64(0.032829857208427966), 'bleu': 0.2661169413763071}\n",
      "\n",
      "===== OOS Metrics (Baseline vs Fine-tuned) =====\n",
      "rouge1      base:  0.027   ft:  0.042   Î”: +0.014\n",
      "rouge2      base:  0.002   ft:  0.008   Î”: +0.006\n",
      "rougeL      base:  0.023   ft:  0.033   Î”: +0.010\n",
      "rougeLsum   base:  0.023   ft:  0.033   Î”: +0.010\n",
      "bleu        base:  0.021   ft:  0.266   Î”: +0.245\n",
      "\n",
      "Saved outputs in: swiss_apertus_8b_ft_inductive_smalllm_compare\n",
      "Baseline preds: val_predictions_baseline.jsonl\n",
      "Finetuned preds: val_predictions_finetuned.jsonl\n",
      "LoRA adapter: adapter/\n",
      "\n",
      "===== Example Outputs =====\n",
      "\n",
      "--- Example 1 ---\n",
      "Observations: High persistence, non-stationarity (ADF pâ‰ˆ0.41), clustered 2008â€“09 change-points, weak seasonality, ...\n",
      "Question: What best explains the observed dynamics: calendar effects, random noise, or macro regime shifts?\n",
      "Reference: Macro regime shifts tied to business/credit cycles best explain the data; calendar effects are secondary.\n",
      "Baseline: The observed dynamic is most likely a combination of these factors:\n",
      "Fine-tuned: Macro regime changes best explain the persistent, multi-annual pattern. Seasonal and short-term shocks are unlikely to drive the trend. The data suggest a regime-driven, persistent cycle rather than a single event-driven effect. This raises confidence that macro forces dominate over calendar drift. â†µ\n",
      "\n",
      "--- Example 2 ---\n",
      "Observations: Across the labeled churn dataset, segmented analyses repeatedly showed: customers with an internatio...\n",
      "Question: What general pattern about churn risk emerges from these repeated cases?\n",
      "Reference: Customers with international plans and many service calls tend to be at higher churn risk, while customers with voice mail plans tend to be retained.\n",
      "Baseline: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Fine-tuned: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "--- Example 3 ---\n",
      "Observations: Forecast trained with an ill-matched hourly horizon on monthly data showed unrealistically low volat...\n",
      "Question: What provisional stance should analysts take toward that flat forecast?\n",
      "Reference: Treat it as defeasibly indicating stabilization; withdraw precision claims if model-horizon mismatch is present.\n",
      "Baseline: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "Fine-tuned: !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "===== Training Complete =====\n",
      "Check the example outputs above to see if fine-tuning improved the answers.\n",
      "Training loss should have decreased during fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finetuned_metrics = eval_metrics(finetuned_preds, val_refs, rouge, bleu)\n",
    "\n",
    "print(\"Fine-tuned metrics:\", finetuned_metrics)\n",
    "\n",
    "# Save fine-tuned predictions\n",
    "with open(os.path.join(OUTPUT_DIR, \"val_predictions_finetuned.jsonl\"), \"w\") as f:\n",
    "    for obs, q, ref, pred in zip(val_obs, val_qs, val_refs, finetuned_preds):\n",
    "        f.write(json.dumps({\n",
    "            \"Training Observations\": obs,\n",
    "            \"Question\": q,\n",
    "            \"Reference\": ref,\n",
    "            \"Prediction\": pred\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save_pretrained(os.path.join(OUTPUT_DIR, \"adapter\"))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"adapter\"))\n",
    "\n",
    "# Print comparison\n",
    "print_compare(baseline_metrics, finetuned_metrics)\n",
    "\n",
    "print(f\"\\nSaved outputs in: {OUTPUT_DIR}\")\n",
    "print(\"Baseline preds: val_predictions_baseline.jsonl\")\n",
    "print(\"Finetuned preds: val_predictions_finetuned.jsonl\")\n",
    "print(\"LoRA adapter: adapter/\")\n",
    "\n",
    "# Print some example outputs for inspection\n",
    "print(\"\\n===== Example Outputs =====\")\n",
    "for i in range(min(3, len(val_obs))):\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"Observations: {val_obs[i][:100]}...\")\n",
    "    print(f\"Question: {val_qs[i]}\")\n",
    "    print(f\"Reference: {val_refs[i]}\")\n",
    "    print(f\"Baseline: {baseline_preds[i]}\")\n",
    "    print(f\"Fine-tuned: {finetuned_preds[i]}\")\n",
    "\n",
    "print(\"\\n===== Training Complete =====\")\n",
    "print(\"Check the example outputs above to see if fine-tuning improved the answers.\")\n",
    "print(\"Training loss should have decreased during fine-tuning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTSVXZGBGJI3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "MrXV_rpxGJGi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:weightwatcher:PyTorch is available but CUDA is not. Defaulting to NumPy for SVD\n",
      "WARNING:weightwatcher:Import error , reetting to svd accurate methods\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on macOS.\n",
      "Running on macOS.\n"
     ]
    }
   ],
   "source": [
    "import weightwatcher as ww\n",
    "base_watcher = ww.WeightWatcher(model=baseline_model)\n",
    "base_details = base_watcher.analyze()\n",
    "base_summary = base_watcher.get_summary(base_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "watcher = ww.WeightWatcher(model=model)\n",
    "details = watcher.analyze()\n",
    "summary = watcher.get_summary(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_norm': np.float64(2.557011775868817),\n",
       " 'alpha': np.float64(6.332740802794254),\n",
       " 'alpha_weighted': np.float64(3.8719353960280394),\n",
       " 'log_alpha_norm': np.float64(4.251105918200468),\n",
       " 'log_spectral_norm': np.float64(0.7483215650030496),\n",
       " 'stable_rank': np.float64(84.57115935377053)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_norm': np.float64(1.2556405013247842),\n",
       " 'alpha': np.float64(6.067527066402183),\n",
       " 'alpha_weighted': np.float64(0.44905566868882674),\n",
       " 'log_alpha_norm': np.float64(0.8055762928364159),\n",
       " 'log_spectral_norm': np.float64(-0.05616470487310674),\n",
       " 'stable_rank': np.float64(44.85347772637995)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10 Mimesis",
   "language": "python",
   "name": "mimesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01270c24ebb94ccf8ac18553ffd6f127": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0170fbfab7d84acb9aea90af6cfe8ac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "01b7f699ab264d00b6caa17de44b5998": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0356ada1f1db4be5915430571aed376b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0359068a3891480293de86020984b66f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0496113c98fa43d68845109e0a2e1399": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "075f39c701714e2bac541e0290a686a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_142a6f0fc7c5477587bb8db7a80f800d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d80007f7a2f6471bb06032ff16e880ff",
      "value": "â€‡8.15k/?â€‡[00:00&lt;00:00,â€‡955kB/s]"
     }
    },
    "08fa103731d64465a0f0af86e625fd37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bdab12747cd4d1e9d352ca569857d37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10b54896c99541868d7e42ef247abe8e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ae3f035d2d84f2ebb2a530a1ba6775f",
      "value": "tokenizer.json:â€‡"
     }
    },
    "0c0ab7d35d7b4270844abb3a1ff16cea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d4a344223ac443087ad45b49819fed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "10b54896c99541868d7e42ef247abe8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "128b922e6719460abf38f59f90afa141": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "131f33981c024d74a71c456b84be64ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_22bd82b7046a4163888dbf4df722f189",
       "IPY_MODEL_ce7471ce4c9e448e9a0f5870a34b9f29",
       "IPY_MODEL_8662c5aac3a54da89a383f773c20f802"
      ],
      "layout": "IPY_MODEL_bb0a6728035949419b53fd5ecaf39b19"
     }
    },
    "142a6f0fc7c5477587bb8db7a80f800d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b86021cf0e4ce9b6268fa3219f6a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0356ada1f1db4be5915430571aed376b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c72d54cb5f3e4d40b493c873a91fede9",
      "value": "tokenizer_config.json:â€‡"
     }
    },
    "195e6762c5fe4ef6b3610a7fba603a39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_826d0838dc55426798bb9a64516fe8d8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fba88cc6c1e74832be0d04f5034ad784",
      "value": "vocab.json:â€‡"
     }
    },
    "1aaf1c10e76a409f9eb3cb4d2fca4c3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "204ba879c2f640d5829329dfaefa459c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21eafa9e2c624b4d90786f0e03498aa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22968273507842a086ee0c1972f76a8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60b3e147812e4ac8ba56e94bb939f341",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1aaf1c10e76a409f9eb3cb4d2fca4c3d",
      "value": 1
     }
    },
    "22bd82b7046a4163888dbf4df722f189": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_845154e7b9364b3ab7aa50bcd7c22b88",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_416dd330e80347a88e4fb6b4a0971566",
      "value": "generation_config.json:â€‡100%"
     }
    },
    "27d8c97e9dea4fe3aeba4465acb82bf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "27f8e121a7034eed857d4e9fc5e1d2da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01b7f699ab264d00b6caa17de44b5998",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f0bd5b80b1848c08ca5df3906845641",
      "value": 1
     }
    },
    "296625f11fff40289d289d6d6216cf05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e98521c424e486b8dc57cde87f988f8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c688a09748db4a56a4b4120722c0a00b",
      "value": "Downloadingâ€‡builderâ€‡script:â€‡"
     }
    },
    "2eb4a2e275044d6f84ee610078a3ff52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2feb78d47e974a0ab763da474efe69d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba113e9d81c24a2292d189d8a4179d13",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_480e8943a95e4eb58a1581e6ec88f17e",
      "value": "â€‡660/660â€‡[00:00&lt;00:00,â€‡76.3kB/s]"
     }
    },
    "32af97df10f942be899dec45a3c0998b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dae40a95088f4887a96553aef9ed29b0",
       "IPY_MODEL_ae0791aee6cd4cdda34298f2e15a753b",
       "IPY_MODEL_075f39c701714e2bac541e0290a686a8"
      ],
      "layout": "IPY_MODEL_2eb4a2e275044d6f84ee610078a3ff52"
     }
    },
    "38d04e5463744d3f88ba6eb44ccf38b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3994b54476f04c3ca9e94aceeb4d57dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73cd45a3b06f4a69ab88078c6c0a8e3b",
      "max": 3087467144,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_63258537bf3846fa80c246dc386cbf09",
      "value": 3087467144
     }
    },
    "3d068bd55fda46c8b7f7103360273068": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6229068e4ff64754afbc59b87bd25fe0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0170fbfab7d84acb9aea90af6cfe8ac9",
      "value": 1
     }
    },
    "3e349c08386b4c16be10fdc1a1a91c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b0c3f95d29b4da9a28e0235f35a3024",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0359068a3891480293de86020984b66f",
      "value": "â€‡6.27k/?â€‡[00:00&lt;00:00,â€‡483kB/s]"
     }
    },
    "416dd330e80347a88e4fb6b4a0971566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "480e8943a95e4eb58a1581e6ec88f17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48c3d51ac541454d8198991326362c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c27d4bad3c54404a16ba495237d57eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c46cefbfd5847c9919861085ec9c202": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f47112e71024fc0b8a15b63e6a1f904": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "585c22b39a48403dadfed290ce562087": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b0c3f95d29b4da9a28e0235f35a3024": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eb7823cfc4f4f409bba02a87f4c6edd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60239336787f4ec9aa23dd423f8cadea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_195e6762c5fe4ef6b3610a7fba603a39",
       "IPY_MODEL_73f4c63ba2584fc18c238e9a415e6f80",
       "IPY_MODEL_af95dfe9d015476c9d4028d08acc3808"
      ],
      "layout": "IPY_MODEL_9561d1e3450b4efab66428acb50a5b2e"
     }
    },
    "60b3e147812e4ac8ba56e94bb939f341": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "6229068e4ff64754afbc59b87bd25fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "63258537bf3846fa80c246dc386cbf09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63b8888f57b349f48d6188ad4972943f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17b86021cf0e4ce9b6268fa3219f6a72",
       "IPY_MODEL_3d068bd55fda46c8b7f7103360273068",
       "IPY_MODEL_ae050d75805644e0ae67b049274f663d"
      ],
      "layout": "IPY_MODEL_d6b60c1a50b34be3b95483f40c6f917c"
     }
    },
    "66334026a6344f99811b85dea929fb3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79373e72d9a2414a9a2c0200a141e7b5",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4c46cefbfd5847c9919861085ec9c202",
      "value": "â€‡1.67M/?â€‡[00:00&lt;00:00,â€‡42.6MB/s]"
     }
    },
    "6ae3f035d2d84f2ebb2a530a1ba6775f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e98521c424e486b8dc57cde87f988f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73cd45a3b06f4a69ab88078c6c0a8e3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73f4c63ba2584fc18c238e9a415e6f80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27d8c97e9dea4fe3aeba4465acb82bf6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_128b922e6719460abf38f59f90afa141",
      "value": 1
     }
    },
    "74b7e62cf79345db93b297e9d11b0fc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "760d47271daf4e8d85123cdc5aa60066": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94fb311bd9a344d8b973b76d8ee9b4c2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f594598d2e834e7dbcaa40a2b7c4df35",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "79373e72d9a2414a9a2c0200a141e7b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7941de3cc39841f28ed46edd081de5b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79c890e48ed6498fbbfcbb850852e85e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fd2fd1d06fa4a4b8936d306d0d7e5b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_760d47271daf4e8d85123cdc5aa60066",
       "IPY_MODEL_3994b54476f04c3ca9e94aceeb4d57dc",
       "IPY_MODEL_a96165cd912d43c9b2006e4f4e3a02a6"
      ],
      "layout": "IPY_MODEL_74b7e62cf79345db93b297e9d11b0fc6"
     }
    },
    "826d0838dc55426798bb9a64516fe8d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "845154e7b9364b3ab7aa50bcd7c22b88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8662c5aac3a54da89a383f773c20f802": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7941de3cc39841f28ed46edd081de5b4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d3e5253af22c4937809d3fa1fa7c17c3",
      "value": "â€‡242/242â€‡[00:00&lt;00:00,â€‡31.7kB/s]"
     }
    },
    "89485c97ce8d40c298081aa2f50dc0d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_296625f11fff40289d289d6d6216cf05",
       "IPY_MODEL_ee3f6dd5d1854e70ad0ec7f9f833b16b",
       "IPY_MODEL_3e349c08386b4c16be10fdc1a1a91c1f"
      ],
      "layout": "IPY_MODEL_d80e579ebdcd42f8a4cdbf5025f5a060"
     }
    },
    "94fb311bd9a344d8b973b76d8ee9b4c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9561d1e3450b4efab66428acb50a5b2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96468ec145b441a59ec465147a18b473": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9d397152da4a06b22fed13a61c2fdb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9f0bd5b80b1848c08ca5df3906845641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5c03a39ca3c401fadaf772eadd48705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79c890e48ed6498fbbfcbb850852e85e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b93c9b095f6b4b419f0b190ef5d75930",
      "value": "â€‡7.03M/?â€‡[00:00&lt;00:00,â€‡62.5MB/s]"
     }
    },
    "a96165cd912d43c9b2006e4f4e3a02a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bec9dae8c0e545ca8c836eb43db0f3d1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d12770ffbc544bf1b2c819e86cf473a9",
      "value": "â€‡3.09G/3.09Gâ€‡[00:39&lt;00:00,â€‡21.7MB/s]"
     }
    },
    "aa2ec039a26e4990a0b3f9d86c22817d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae050d75805644e0ae67b049274f663d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fad327a9f8594bddb8d251a29d628247",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4f47112e71024fc0b8a15b63e6a1f904",
      "value": "â€‡7.30k/?â€‡[00:00&lt;00:00,â€‡794kB/s]"
     }
    },
    "ae0791aee6cd4cdda34298f2e15a753b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b9d397152da4a06b22fed13a61c2fdb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0496113c98fa43d68845109e0a2e1399",
      "value": 1
     }
    },
    "af95dfe9d015476c9d4028d08acc3808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5eb7823cfc4f4f409bba02a87f4c6edd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_08fa103731d64465a0f0af86e625fd37",
      "value": "â€‡2.78M/?â€‡[00:00&lt;00:00,â€‡3.92MB/s]"
     }
    },
    "b1108d37b1fb4d75ae85646f4907120c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f07d1f229e83424a9cf8090220ce1f83",
       "IPY_MODEL_27f8e121a7034eed857d4e9fc5e1d2da",
       "IPY_MODEL_66334026a6344f99811b85dea929fb3a"
      ],
      "layout": "IPY_MODEL_01270c24ebb94ccf8ac18553ffd6f127"
     }
    },
    "b74bc3c945cf47cf9b7e7cc5dc9d27fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b93c9b095f6b4b419f0b190ef5d75930": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba113e9d81c24a2292d189d8a4179d13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb0a6728035949419b53fd5ecaf39b19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bec9dae8c0e545ca8c836eb43db0f3d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c688a09748db4a56a4b4120722c0a00b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c72d54cb5f3e4d40b493c873a91fede9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce602d66b833431cad5a002513eed8ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce7471ce4c9e448e9a0f5870a34b9f29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38d04e5463744d3f88ba6eb44ccf38b8",
      "max": 242,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_585c22b39a48403dadfed290ce562087",
      "value": 242
     }
    },
    "d12770ffbc544bf1b2c819e86cf473a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3e5253af22c4937809d3fa1fa7c17c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6b60c1a50b34be3b95483f40c6f917c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d80007f7a2f6471bb06032ff16e880ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d80e579ebdcd42f8a4cdbf5025f5a060": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d99e1da787824dda88ac629440bbb6be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dae40a95088f4887a96553aef9ed29b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d99e1da787824dda88ac629440bbb6be",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_21eafa9e2c624b4d90786f0e03498aa3",
      "value": "Downloadingâ€‡builderâ€‡script:â€‡"
     }
    },
    "e24c12bde94a4305bb546c886da4ab4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0bdab12747cd4d1e9d352ca569857d37",
       "IPY_MODEL_22968273507842a086ee0c1972f76a8f",
       "IPY_MODEL_a5c03a39ca3c401fadaf772eadd48705"
      ],
      "layout": "IPY_MODEL_204ba879c2f640d5829329dfaefa459c"
     }
    },
    "e59a8a878f6f4abdb08bbf2688ae8bb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f85d0290c37947baabae42394b8cda83",
       "IPY_MODEL_ecf312119cdf4d97a2aca40eba42bb49",
       "IPY_MODEL_2feb78d47e974a0ab763da474efe69d9"
      ],
      "layout": "IPY_MODEL_0c0ab7d35d7b4270844abb3a1ff16cea"
     }
    },
    "ecf312119cdf4d97a2aca40eba42bb49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa2ec039a26e4990a0b3f9d86c22817d",
      "max": 660,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d4a344223ac443087ad45b49819fed9",
      "value": 660
     }
    },
    "ee3f6dd5d1854e70ad0ec7f9f833b16b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b74bc3c945cf47cf9b7e7cc5dc9d27fd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48c3d51ac541454d8198991326362c1d",
      "value": 1
     }
    },
    "f07d1f229e83424a9cf8090220ce1f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8587ec101a54fe7a37c243b5c142f6f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ce602d66b833431cad5a002513eed8ee",
      "value": "merges.txt:â€‡"
     }
    },
    "f594598d2e834e7dbcaa40a2b7c4df35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f8587ec101a54fe7a37c243b5c142f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f85d0290c37947baabae42394b8cda83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96468ec145b441a59ec465147a18b473",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4c27d4bad3c54404a16ba495237d57eb",
      "value": "config.json:â€‡100%"
     }
    },
    "fad327a9f8594bddb8d251a29d628247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fba88cc6c1e74832be0d04f5034ad784": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
